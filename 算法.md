* **许多问题都可以作为一般性问题的特例来解决**。例如，寻找序列101, 12, 144, 212, 98 中最大整数的问题。这是寻找整数序列中最大整数问题的一个特例。为解决这个一般性问题， 我们必须给出一个算法，它指定了一系列步骤来解决这个一般性问题。本书我们将研究解决许 多不同类型问题的算法。

* 对于一个算法，需要重点考虑的是其**计算复杂度**，它用来衡量该算法在解决一定规模问题时所需要的**处理时间**和**计算机存储空间**。为了度量算法的复杂度，我们使用大$O$和大$\theta$记号.

* 离散数学中有多种一般性问题。例如，已知一串整数，求最大的一个；已知一个集合，列出其所有子集；给定一个整数集合，把这些整数从小到大排序；已知一个网络，找出两个顶点之间的最短路径等。遇到这样的问题时，首先要做的就是**构造一个模型把问题转换为数学问题**。建立合适的数学模型只是解题的第一步。完整的解题还需要**利用这一模型解决一般性问题的方法**。理想的情况是需要一个过程，它能够遵循一系列步骤导致找到所求的答案。这一系列步骤就称为一个**算法**(algorithm). 

* **算法是进行一项计算或解决一个问题的准确指令的有限序列**。

* 算法可直接用中文描述需要用到一系列步骤。也可以用一种计算机语言来描述。但是当这样做时，只能使用这种语言所允许的指令。这样做常常导致算法的描述既复杂而又难以理解。

  * 在一个有限整数序列中寻找最大值的算法。

  * 解执行下面的步骤

    1. 设临时最大值等于序列中第一个整数。（整个过程的每一阶段，临时最大值都等于已检 查过的最大整数。）

    2. 将序列中的下一个整数与临时最大值比较，如果这个数大于临时最大值，置临时最大 值为这个整数。

    3. 如果序列中还有其他整数，重复前一个步骤。
    4. 当序列中不再有其他整数时停止。此刻的临时最大值就是序列中的最大整数。

    ```
    procedure max（a1, a2 , …，an: 整数） 
    max := a1
    for i := a2 to an
    	if max < ai then max := ai
    return max {max 是最大元素}
    ```

* **算法的性质**   算法一般都共有一些性质。当描述算法时牢记这些性质是有益的。这些性质是：

  * **输入**    算法从一个指定的集合得到输入值。
  * **输出**    对每个输入值集合，算法都要从一个指定的集合中产生输出值。输出值就是问题的解。
  * **确定性**    算法的步骤必须是准确定义的。
  * **正确性**    对每一组输入值，算法都应产生正确的输出值。
  * **有限性**    对任何输入算法都应在有限（可能很多）步之后产生期望的输出。
  * **有效性**    算法的每一步都应能够准确地在有限时间内完成。

  * **通用性**    算法过程应该可以应用于期望形式的所有问题，而不只是用于一组特定的输入值。

* **搜索算法**    在有序表中定位一个元素的问题。
  
* 在不同元素 $a_0, a_1, a_2, ..., a_n$ 的表中定位元素 x ,或判定 x 不在该表中。这一搜索问题的解就是表中等于x的那一项的位置（即如果 $x = a_i$ 那么, $i$ 就是解），而当x不在表中时了为0。
  
* **线性搜索**    将介绍的第一个算法称为线性搜索或顺序搜索算法。线性搜索算法从比较 x 和 $a_1$开始。如果$x = a_1$ ,那么解就是$a_i$的位置，即1。当 $x \neq a_1$时，比较 x 和 $a_2$。如果 $x = a_2$,解就是$a_2$的位置，即2。当$x \neq a_2$时，比较x与 $a_3$。继续这一过程，逐一比较 x 和表中的每一 项直到找到匹配为止，这里解就是该项的位置除非没有匹配。如果已捜索了整个表却不能定位 x,那么解是0。

  ```
  procedure linear search (x： 整数，a1,a2,...,an:不同整数)
  i := 1
  while (i <= n 和 x != ai)
  	i := i+l
  if i <= n then location := i
  else location :=0
  return location  {location是等于 x 的项的下标，或者是0如果找不到x}
  ```

* **二分搜索**    现在考虑另一个搜索算法。当表中各项以升序出现时可以用这一算法。这个算法称为**二分搜索算法**。它是通过比较要搜索的元素与表的中间项进行的。然后此表就分成两个较小的长度相等的子表，或其中较短的列表比另一个少一项。根据与中间项的比较结果， 可以将搜索局限于一个合适的子表继续进行。

  * 要在表$a_0, a_1, a_2, ..., a_n$中搜索整数 x ，其中$a_0 \lt a_1  \lt a_2  \lt ... \lt a_n$,  从比较x 和列表的中间项$a_m$开始，其中 $m = \lfloor(n+1/2\rfloor)$。 如果 $x \gt a_m$,  搜索可以限定在列表的后半段，即$a_{m+1}, a_{m+2}, ..., a_n$，如果 x 不大于$a_m$, 搜索可限定在列表的前半段，即为 $ a_0, a_1, ..., a_m$。现在搜索的范围限于一个不超过「n/2］个元素的列表。用同样的过程，比较了和这个限定表的中间项。然后把搜索限于该限定表的前半段或后半段。这样重复直到得到只含一项的列表。然后判断这项是否就是了。

  ```
  procedure binary search (x :整数，a1, a2, ..., an:递增整数)
  i := 1;
  j := n;
  while i < j
  	m :=  L（i+j）/2」
  	if x > am then i := m+l
      else j := m
  if x= ai then location := i
  else location := 0
  return location {location是等于x的项ai,的下标i; 或是0, 如果找不到z}
  ---
  通过不断缩小被搜索的序列而进行的。在任何阶段都只有从ai到aj的这些项需要考虑。换言之，i和j分别是剩余项的最小和最大下标. 不断缩小需搜索的序列，直到序列中只剩下一项为止。此时，需要一次比较来看这一项是否等于x。
  ```

* **排序**   假定有一个集合元素的列表。再假设有一种方式可以给集合的元素排序。排序(sorting)就是把这些元素排成一个列表，其中元素按照升序排列。 

* **冒泡排序**    冒泡排序(bubble sort)是最简单的，但不是最有效的排序算法之一。冒泡排序通过**连续比较相邻的元素**，如果相邻元素顺序不对就交换相邻元素，从而把一个表排列成升 序。为了实现冒泡排序，我们执行基本操作，即交换一个较大元素与紧跟其后的较小元素，从表头开始完整地执行一遍。迭代这个过程直到排序完成。可以 想象把表中的元素排成一列。在冒泡排序中，较小的元素随着与较大的元素交换而“冒泡”到顶端。较大的元素则“下沉'‘到底部。

  ```
  procedure bubblesort (a1, a2,…,an: 实数, n >= 2） 
  	for i := 1 to n-1
  		for j := 1 to n-i
          	if aj < a（j+1） then 交换 aj, a(j+1)
  {a1, a2,…,an 升序排列}
  ```

* **插入排序**    插入排序（insert sort）是一种简单的排序算法，但通常不是最有效的。为了给 n 个元素的表排序，插入排序从第二个元素开始。插入排序将这第二个元素与第一个元素比较：如果它不大于第一个元素，就把它插入到第一个元素前面；如果它大于第一个元素，就把它插 入到第一个元素后面。此时前两个元素顺序正确。然后第三个元素与第一个元素比较，如果它大于第一个元素，再与第二个元素比较；它将插入到前三个元素中的正确位置上。一般来说，在插入排序第 j 步上，表的第 j 个元素插入到已经排序的 j一1个元素的表的正确位置上。为了在表中插入第 j 个元素，使用线性搜索技术。从表头开始，第 j 个元素依次与已经排序的 j - 1个元素比较，直到发现第一个不小于这个元素的元素为止，或 者直到这个元素已经与所有 j-1个元素都比较过为止。第 j 个元素就被插入到正确位置上使得前 j个元素排好顺序。继续该算法直到最后一个元素被放置到相对于前 n -1 个元素已经排 序的表中的正确位置上。 (将元素分成两部分， 一部分已经完成排序， 另一部分乱序， 不断从乱序中移除一个元素并放入排好序的元素列表的正确位置中)

  ```
  procedure insertion sort (a1, a2,...,an :实数, n >= 2） 
  	for j := 2 to n
  		i := 1
  		while ai > aj 且 i < j
  			i := i+1
  		m := aj
  		for k := 0 to j-1
  			a{j-k} := a{j-k+1}
          ai := m
  {a1, a2, ..., an已排好序}
  ```

* **贪婪算法**    一种最简单的方法常常能导致最优化问题的一个解。这种方法在每一步

  都选择最好的选项，而不是通盘考虑可能导致最优解的全部步骤序列。**在每一步都选择看起 来最好的选项的算法称为贪婪算法**（greedy algorithm）。一旦贪婪算法求出了一个可行解， 就要确定它是否找到了一个最优解。为此，要么证明这个解是最优的，要么证明该算法产生 了一个非最优解的反例。

* 如果力是 n 整数，则用25美分、10美分、5美分和1美分，并用尽可能少的硬币找 n 美分零钱中，至多有 2 个10美分、至多有1个5美分、至多有4个1美分硬币，并且不 可能同时有 2 个10 美分和1个5美分硬币。用10美分、5美分和1美分硬币找的零钱总额不会超过24美分。

* 贪婪算法产生使用尽可能少硬币的找零方案。

  ```
  procedure change (c1, c2, ..., cr:硬币的面值，其中 c1>c2>...>cr；n: 正整数)
  for i := 1 to r
  	di = 0 {统计使用面值为ci的硬币数｝
  	while n >= ci
  		di := di + 1
  		n := n - ci
  {di为零钱面值为 ci的硬币的数量，i = 1,2,...,r}
  ```

* 讲座安排

---

##### 函数的增长

* **解决一个问题所需的时间不仅仅取决于所用的操作步数。这个时间还取决于用于运行实现一个算法的程序的硬件和软件**。 但是，当我们更改用于实现算法的硬件和软件时，可以**通过给先前估计所需时间乘以一个常数来精确地估算求解规模为 n 的问题所需的时间.** 例如，在一台超级计算机上求解规模为 n 的问题可能比在一台个人计算机上快100万倍。而这100万的因子并不取决于 n（也许会有一 点点的依赖关系）。使用本节介绍的大$O$记号有一个好处，就是可以估计一个 函数的增长而不用担心常数因子或低阶项。这意味着使用大 $O$ 记号不用担心实现算法所用的 硬件和软件。另外，使用大$O$ 记号时我们可以假设算法中使用的不同操作都花费相等的时间，这大大简化了分析。

* 大O记号广泛用于**估计当输入增长时一个算法所用的操作的数量**。借助于这个记号，就能够**判定当输入规模增大时用一个特定算法来求解该问题是否实际可行**。另外，使用大O记号， 可以**比较两个算法以判断当输入规模增大时哪个算法更有效**。例如，如果求解一个问题我们有 两个法，一个使用 $100n^2 + 17n + 4$ 步运算，另一个使用 $n^3$ 步运算，那么大O记号可以帮助我们了解到当 n 很大时第一个算法所使用的运算会少得多，即使对于小的 n 值，比如 n = 10,第 一个算法使用的运算会比较多。

* 令 $f$ 和 $g$ 为从整数集或实数集到实数集的函数。如果存在常数 C 和 k 使得只要当 $x \gt k$时, 就有
  $$
  |f(x)| \le C|g(x)|
  $$
  我们就说$f(x)$是$O(g(x))$的。

* 直觉上，$f(x)$是$O(g(x))$的 定义是说当工无限增长时$f(x)$的增长慢于$g(x)$的 某个固定的倍数。

* 大 O 记号定义中的常数 C 和 k 称为$f(x)$是$O(g(x))$的**关系的凭证**（witness）. 为了建立 $f(x)$是$O(g(x))$, 我们只需要这一关系的一对凭证。即要证明$f(x)$是$O(g(x))$的，我们需要 找出一对常数 C 和 k ,即凭证，使得只要当 $x \gt k$ 时就有 $|f(x)| \le C|g(x)|$。

  注意当有$f(x)$是$O(g(x))$的关系的一对凭证时，就会有无限多对凭证。要明白这一点， 注意如果 C 和 k 是一对凭证，那么任意一对$C'$和$k'$（其中$C \lt C', k \lt k'$）也是一对凭证，因为只要当 $x \gt k' \gt k$ 时就有 $|f(x)| \le C|g(x)| \le C'|g(x)|$

* 利用大 O 记号的定义求一对凭证的一种有用方法是先选择 kl 的值使得当 x>k 时容易估计 $f(x)$ 的大小，再看看能否用这个估计找出 C 的值使得对于 $x \gt k$ 时有 $|f(x)| \le C|g(x)|$.

* 当 $f(x)$是 $O(g(x)) $的，并且对于足够大的 x 有函数 $h(x)$的绝对值大于 $g(x) $,则有/(抄 是$f(x)$是 $O(h(x)) $的。换言之，$f(x)$是 $O(g(x)) $的这一关系中的函数 $g(x)$ 可以替换为具有更大绝对值的函数。要看清这一点，注意如果 $|f(x)| \le C|(g(x))|, x \gt k; \forall x \gt k, |h(x)| \gt |g(x)|, 那么 |f(x)| \le C|h(x)|, x \gt k$。故，$f(x)$是 $O(h(x)) $的。当使用大O记号时，在$f(x)$是 $O(g(x)) $的这一关系中**函数 g 的选择应该尽可能的小**。

* 一些重要函数的大O估算
  * $f(x) = a_nx^n + a_{n-1}x^{n-1} + ... + a_1x + a_0$, 那么 $f(x)$是 $O(x^n) $的。
  * 用大O记号估计前 n个正整数之和: 由于前 n 个正整数之和中的每个整数都不超过 n，所以 $ 1 + 2 + 3 + ... +n \le n + n + ... + n = n^2$,  $f(\sum_{i=1}^n i)$是 $O(n^2) $的
  * $f(x) = n!, n! = 1*2*...*n \le n*n*n*...*n = n^n$,  $f(n!)$是 $O(n^n) $的
  * $f(x) = logn, n \lt 2^n (任意n); logn \lt n$,  $f(logn)$是 $O(n) $的
  * $f(x) = log_bn = logn/logb \lt n/ logb$,,  $f(log_bn)$是 $O(n) $的
* $f(x)$为多项式， 若 d > c> 1, 则$f(n^c)$是$O(n^d)$的, $n^d$不是$O(n^c)$的。
  
* 用于估计的常用函数

  * $1, logn, n, nlogn, n^2, 2^n, n!$

* **函数组合的增长**    许多算法都由两个或多个独立的子过程组成。计算机使用这样的算法来求解一定输入规模的问题时所需要的步数是这些过程所使用的步数之和。要用大O估计所需要的步数，就需要找 出每个子过程所用步数的大 O 估计，然后再把这些估计组合起来。

* 假定$f_1(x)$是 $O(g_1(x))$的，$f_2(x)$是$O(g_2(x))$的，那么$(f_1 + f_2)(x)$是

  $O(max(|g_1(x)|, |g_2(x)|))$的。

* 假定$f_1(x)$是 $O(g_1(x))$的，$f_2(x)$是$O(g_2(x))$的，那么$(f_1f_2)(x)$是

  $O((g_1g_2)(x))$的。

* 假定$f_1(x)$和$f_2(x)$是$O(g(x))$的，那么$(f_1 + f_2)(x)$是$O(g(x))$的。



* 令 $f(x)$  和  $ g(x) $ 为从整数集合或实数集合到实数集合的函数。如果存在正常数C和k使得当$x > k$ 时有, $|f(x)| \ge C|g(x)|$,  我们说$f(x)$  是  $ \Omega g(x) $ 的。

* 大O和大$\Omega$记号之间有很强的关联。特别是$f(x)$是$O(g(x))$的当且仅当$ g(x) $ 是

  $\Omega f(x)$的。

* 令 $f(x)$  和  $ g(x) $ 为从整数集合或实数集合到实数集合的函数。如果$f(x)$是$O(g(x))$的且$f(x)$  是  $ \Omega g(x) $ 的，我们就说$f(x)$  是  $ \theta g(x) $ 的。当$f(x)$  是  $ \theta g(x) $ 的，即$f(x)$ 是 $g(x)$ 阶的，或$f(x)$ 和 $g(x)$ 是同阶的。

  当$f(x)$  是  $ \theta g(x) $ 的，同样会有 $g(x)$  是  $ \theta f(x) $ 的。注意, 当且仅当存在实数 $C_1$和$C_2$以及一个正实数 k 使得当 $x\gt k$时有
  $$
  C_1(g(x)) \le |f(x)| \le C_2|g(x)|
  $$

* 令 $f(x) = a_nx^n + a_{n-1}x^{n-1} + .... + a_1x + a_0$, 其中 $a_0, a_1, ..., a_m为实数且a_n \neq 0.$ 则$f(x)$ 是 $x^n$阶的。

* 

